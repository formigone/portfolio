{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1cf10c5-7f92-42f8-be49-90843a78731d",
   "metadata": {},
   "source": [
    "# Keras R&D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e404ee9-8bbc-435d-ae70-008532e9d106",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221b31fa-1c75-45b2-abfe-5da23be13a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = '''\n",
    "In a quiet village, a curious boy named Liam had a loyal horse named Blaze.\n",
    "Together, they discovered an ancient device that projected holograms of the human brain, illustrating the wonders of machine learning.\n",
    "One night, while experimenting, the device activated, propelling them into the future.\n",
    "In this world, machines and humans coexisted harmoniously, their minds intertwined through advanced AI.\n",
    "\n",
    "Liam learned that this future was shaped by understanding the brain's intricacies.\n",
    "As they time-traveled back, armed with knowledge, they set out to share their discoveries, ensuring a future where technology and humanity thrived together,\n",
    "guided by wisdom and compassion.\n",
    "\n",
    "In a quiet village nestled between rolling hills and dense forests, a boy named Liam lived with his parents. His best friend and constant companion was a majestic horse named Blaze, with a coat as black as night and eyes that sparkled with intelligence. Liam had always been fascinated by the mysteries of the human mind and the promise of technology. His father, a scientist, had instilled in him a deep love for discovery and innovation.\n",
    "\n",
    "One crisp autumn day, while exploring the outskirts of the village, Liam stumbled upon a hidden cave. Inside, he found a peculiar device covered in dust and cobwebs. The device had a series of buttons and a holographic projector. Intrigued, Liam brought it back to his father, who recognized it as an ancient relic from a long-forgotten civilization. This device, his father explained, could project detailed images of the human brain and was rumored to have the ability to manipulate time.\n",
    "\n",
    "Liam and his father spent weeks studying the device, trying to unlock its secrets. One night, while experimenting with different settings, they accidentally activated it. A blinding light enveloped Liam and Blaze, and they were transported through a vortex of time and space. When the light faded, they found themselves in a world unlike anything they had ever seen.\n",
    "\n",
    "They had arrived in a future where technology and humanity had evolved together in perfect harmony. Skyscrapers touched the clouds, and advanced machines coexisted with humans, their minds connected through neural interfaces powered by sophisticated AI. People moved about with an air of serenity and purpose, their lives enriched by the seamless integration of technology.\n",
    "\n",
    "Liam was fascinated by this future. He learned that the advancements were made possible by a profound understanding of the human brain's intricacies. Scientists had used machine learning to decode the brain's mysteries, creating AI that could augment human abilities and foster unprecedented innovation. This future society had eradicated diseases, solved complex global issues, and achieved a level of prosperity and happiness that Liam had never imagined.\n",
    "\n",
    "During their stay, Liam and Blaze met a wise old scientist named Dr. Elena. She explained that this harmonious future was not always guaranteed. It was the result of generations of effort, guided by the lessons learned from the past. Dr. Elena showed Liam how they used machine learning to predict and prevent potential crises, ensuring a stable and prosperous world.\n",
    "\n",
    "Inspired by what he had learned, Liam realized the importance of understanding the human brain and harnessing the power of technology for good. Dr. Elena offered them a chance to return to their own time, armed with the knowledge they had gained. With a heavy heart but a sense of purpose, Liam and Blaze stepped back into the vortex, ready to share their discoveries.\n",
    "\n",
    "Upon returning to their village, Liam and his father began working tirelessly to apply the insights from the future. They developed new ways to study the brain, creating early versions of neural interfaces and AI-driven solutions to improve people's lives. The villagers were initially skeptical, but they soon saw the benefits of these innovations.\n",
    "\n",
    "Years passed, and Liam grew into a wise and respected scientist, much like Dr. Elena. Blaze remained by his side, a symbol of their incredible journey. Together, they inspired a new generation of thinkers and dreamers, ensuring that their world would one day achieve the harmonious future they had glimpsed.\n",
    "\n",
    "Liam never forgot the lessons he learned during his time travel adventure. He knew that the key to a brighter future lay in understanding the past, embracing the present, and always striving for progress with wisdom and compassion. As he looked out over the village, now a thriving hub of innovation, he knew that he and Blaze had set the wheels of destiny in motion, creating a legacy that would endure for generations to come.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a51e2d-fb2e-4564-9eba-91b628eb1f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTextCleaner(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(MyTextCleaner, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        txt = tf.strings.lower(inputs)\n",
    "        txt = tf.strings.regex_replace(txt, r'[\\.\\,\\n]', ' ')\n",
    "        txt = tf.strings.regex_replace(txt, r'\\b(.*?)\\-(.*?)\\b', r'\\1 <HYPHEN> \\2')\n",
    "        txt = tf.strings.regex_replace(txt, r'\\b(.*?)\\'s\\b', r'\\1 <APOSTROPHE-S>')\n",
    "        txt = tf.strings.regex_replace(txt, r'\\s\\s+', ' ')\n",
    "        txt = tf.strings.strip(txt)\n",
    "        return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5db6757-98d0-4417-bfbe-6b634744e97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(txt: tf.Tensor) -> tf.Tensor:\n",
    "    txt = tf.strings.lower(txt)\n",
    "    txt = tf.strings.regex_replace(txt, r'[\\.\\,\\n]', ' ')\n",
    "    txt = tf.strings.regex_replace(txt, r'\\b(.*?)\\-(.*?)\\b', r'\\1 <HYPHEN> \\2')\n",
    "    txt = tf.strings.regex_replace(txt, r'\\b(.*?)\\'s\\b', r'\\1 <APOSTROPHE-S>')\n",
    "    txt = tf.strings.regex_replace(txt, r'\\s\\s+', ' ')\n",
    "    txt = tf.strings.strip(txt)\n",
    "\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d2c6e6-4763-4196-86dd-1f233d4460d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB = {}\n",
    "txt_cleaner = MyTextCleaner()\n",
    "for line in TEXT.strip().split('\\n'):\n",
    "    if line.strip() == '':\n",
    "        continue\n",
    "\n",
    "    line = tf.constant(line, dtype=tf.string)\n",
    "    # tokens = process_text(line).numpy().decode('utf-8').split(' ')\n",
    "    tokens = txt_cleaner(line).numpy().decode('utf-8').split(' ')\n",
    "    for val in tokens:\n",
    "        VOCAB[val] = VOCAB.get(val, 0) + 1\n",
    "\n",
    "VOCAB = {k: v for k, v in sorted(VOCAB.items(), key=lambda v: (v[1], v[0]), reverse=True)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67320e6e-3d32-4ba0-9b70-05c6f7198e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, v in enumerate(VOCAB.keys()):\n",
    "    print(f'{i+2:>3} {v:<16}', end=' ')\n",
    "    if (i + 1) % 7 == 0:\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638f7aef-d2dc-4669-b4fa-ca18fb6d4ad6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53905a75-be8f-43b9-9a3f-2382388cab41",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_input = tf.constant([[' the brain of ai is, over-time ']], dtype=tf.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101ef115-123c-4a30-99af-3e2da6650478",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_text(sample_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e9b5b3-8ca5-4c76-8a13-4ffdb9c0df4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe926aa-99a5-4f11-a9dc-7eb2aa1e8a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = layers.TextVectorization(\n",
    "    standardize=process_text,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=16,\n",
    "    vocabulary=list(VOCAB.keys()),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd942d1-ce63-4e8b-b11b-2b6302e48762",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec(sample_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58545441-6334-4d53-8855-7c4a657ea3c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ae66e6-532b-42fe-bc21-d2c55bb48a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_my_model():\n",
    "    layer_input = layers.Input(shape=[1], dtype=tf.string)\n",
    "\n",
    "    vec = layers.TextVectorization(\n",
    "        standardize=process_text,\n",
    "        output_mode='int',\n",
    "        output_sequence_length=16,\n",
    "        vocabulary=list(VOCAB.keys()),\n",
    "        name='Vec'\n",
    "    )\n",
    "    embedding = layers.Embedding(input_dim=len(VOCAB) + 2, output_dim=4)\n",
    "    dense = layers.Dense(8, activation='relu')\n",
    "    output_layer = layers.Dense(1, activation='sigmoid')\n",
    "\n",
    "    x = vec(layer_input)\n",
    "    x = embedding(x)\n",
    "    x = tf.reduce_mean(x, axis=1)\n",
    "    x = dense(x)\n",
    "    x = output_layer(x)\n",
    "\n",
    "    return tf.keras.Model(inputs=layer_input, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe5d0a8-8e34-4a50-8b2e-f7e168538490",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self, vocab, version):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.txt_cleaner = MyTextCleaner()\n",
    "        self.vec = layers.TextVectorization(\n",
    "            standardize=None,\n",
    "            output_mode='int',\n",
    "            output_sequence_length=16,\n",
    "            vocabulary=list(VOCAB.keys()),\n",
    "        )\n",
    "        self.embedding = layers.Embedding(input_dim=len(VOCAB) + 2, output_dim=4)\n",
    "        self.dense = layers.Dense(8, activation='relu')\n",
    "        self.output_layer = layers.Dense(1, activation='sigmoid')\n",
    "\n",
    "        self.embedding_output = None\n",
    "        self.vec_output = None\n",
    "        self.txt_post_output = None\n",
    "        self.vocab = vocab\n",
    "        self._version = version\n",
    "\n",
    "    # def get_config(self):\n",
    "    #     config = super(MyModel, self).get_config()\n",
    "        # config.update({'version': self._version})\n",
    "        # return config\n",
    "\n",
    "    def call(self, inputs, return_embedding_output=False, return_vec_output=False, return_txt_output=False):\n",
    "        x = self.txt_cleaner(inputs)\n",
    "        if return_vec_output:\n",
    "            self.txt_post_output = x\n",
    "        else:\n",
    "            self.txt_post_output = None\n",
    "\n",
    "        x = self.vec(x)\n",
    "        if return_vec_output:\n",
    "            self.vec_output = x\n",
    "        else:\n",
    "            self.vec_output = None\n",
    "\n",
    "        x = self.embedding(x)\n",
    "        if return_embedding_output:\n",
    "            self.embedding_output = x\n",
    "        else:\n",
    "            self.embedding_output = None\n",
    "        x = tf.reduce_mean(x, axis=1)\n",
    "        x = self.dense(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n",
    "    def get_embedding_output(self):\n",
    "        return self.embedding_output\n",
    "\n",
    "    def get_vec_output(self):\n",
    "        return self.vec_output\n",
    "\n",
    "    def get_txt_output(self):\n",
    "        return self.txt_post_output\n",
    "\n",
    "    def get_vocab(self):\n",
    "        return self.vocab\n",
    "\n",
    "    def get_version(self):\n",
    "        return self._version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fc764c-44a6-434b-ad79-dc2985cb0615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_model = build_my_model()\n",
    "# my_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# my_model.summary()\n",
    "\n",
    "# tf.keras.utils.plot_model(my_model, show_shapes=True, show_dtype=True, expand_nested=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d75bf3-8a3b-4228-b5e7-c314a9152189",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f459f4e7-b63c-463b-9547-60af4bc27847",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = tf.constant(['<EMPTY>', '<OOV>'] + [k for k, v in VOCAB.items()])\n",
    "model = MyModel(vocab, tf.constant('1.0.2-dev', dtype=tf.string))\n",
    "model(sample_input, True, True, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a6f47d-7a4c-458f-b998-84d5ef3eb392",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_embedding_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab736e8e-70b6-4b2f-9547-ee11276b90e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_vec_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983bcbce-db9f-44bb-b9ee-8306a2fbec6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_txt_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ca833d-ef9e-45db-afd5-d05837ddb9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c384186d-71a4-4597-8c66-f7e8d7acac4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_vocab()[:32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd0fc55-65e5-4718-8b13-ea339dd0ec2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17569bbb-acba-44f3-98cb-45cd0c9314e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit([['the book'], ['the brain is of time']], [1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba378889-2e8a-4f7a-a7ca-b9cc9322cce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function(input_signature=[tf.TensorSpec(shape=[None, 1], dtype=tf.string)])\n",
    "def serve_model(inputs):\n",
    "    return {\"outputs\": model(inputs), 'version': model.get_version()}\n",
    "\n",
    "@tf.function(input_signature=[tf.TensorSpec(shape=[None, 1], dtype=tf.string)])\n",
    "def serve_embedding(inputs):\n",
    "    model(inputs, True)\n",
    "    return {\"embedding_output\": model.get_embedding_output()}\n",
    "\n",
    "@tf.function(input_signature=[tf.TensorSpec(shape=[None, 1], dtype=tf.string)])\n",
    "def serve_vec(inputs):\n",
    "    model(inputs, False, True)\n",
    "    return {\"vec_output\": model.get_vec_output()}\n",
    "\n",
    "@tf.function(input_signature=[tf.TensorSpec(shape=[None, 1], dtype=tf.string)])\n",
    "def serve_txt(inputs):\n",
    "    model(inputs, False, True)\n",
    "    return {\"txt_output\": model.get_txt_output()}\n",
    "\n",
    "@tf.function(input_signature=[tf.TensorSpec(shape=[None, 1], dtype=tf.string)])\n",
    "def serve_vocab(inputs):\n",
    "    model(inputs, False, True)\n",
    "    return {\"vocab\": model.get_vocab()}\n",
    "\n",
    "@tf.function(input_signature=[tf.TensorSpec(shape=[None, 1], dtype=tf.string)])\n",
    "def serve_guts(inputs):\n",
    "    model(inputs, True, True)\n",
    "    return {\n",
    "        \"embedding_output\": model.get_embedding_output(),\n",
    "        \"vec_output\": model.get_vec_output(),\n",
    "        'txt_output': model.get_txt_output(),\n",
    "        'vocab': model.get_vocab(),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a9924e-cdce-417c-b3ea-42522f6c4225",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('saved_models/gutsy-model', signatures={\n",
    "    \"serving_default\": serve_model,\n",
    "    \"embedding\": serve_embedding,\n",
    "    \"vec\": serve_embedding,\n",
    "    \"txt\": serve_txt,\n",
    "    \"vocab\": serve_vocab,\n",
    "    \"guts\": serve_guts,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7278558f-2481-4b9a-84a5-2234cf055dce",
   "metadata": {},
   "source": [
    "## Load saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d271fc28-e3cd-4333-b40b-28ace074789a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-26 05:36:00.626044: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-26 05:36:01.432353: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ca3314e-78ee-4a56-96af-5ba66aecaeb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-26 05:36:02.216793: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-05-26 05:36:02.216837: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:168] retrieving CUDA diagnostic information for host: ml03\n",
      "2024-05-26 05:36:02.216844: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:175] hostname: ml03\n",
      "2024-05-26 05:36:02.216892: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:199] libcuda reported version is: 460.106.0\n",
      "2024-05-26 05:36:02.216912: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:203] kernel reported version is: 460.106.0\n",
      "2024-05-26 05:36:02.216917: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:309] kernel version seems to match DSO: 460.106.0\n"
     ]
    }
   ],
   "source": [
    "sample_input = tf.constant([\n",
    "    [' The Brain Of AI AI. is, over-time '],\n",
    "    ['Once upon a time there\\'s a mid-century BRAIN from a lot of over-time that he\\'s not there'],\n",
    "], dtype=tf.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c5c3512-0634-4ad8-b778-badc51d0a392",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = tf.saved_model.load('saved_models/gutsy-model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e081446-41c9-4291-8e24-9775cfb57c03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_SignatureMap({'serving_default': <ConcreteFunction signature_wrapper_serve_model(*, inputs) at 0x7F55F04353A0>, 'embedding': <ConcreteFunction signature_wrapper_serve_embedding(*, inputs) at 0x7F55F03FD2B0>, 'vec': <ConcreteFunction signature_wrapper_serve_embedding(*, inputs) at 0x7F55F0364820>, 'txt': <ConcreteFunction signature_wrapper_serve_txt(*, inputs) at 0x7F55F036F1C0>, 'vocab': <ConcreteFunction signature_wrapper_serve_vocab(*, inputs) at 0x7F55F4346130>, 'guts': <ConcreteFunction signature_wrapper_serve_guts(*, inputs) at 0x7F55F03FAA60>})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.signatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f068c26f-5c91-4c71-ad2e-aef8f0b72f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = new_model.signatures['serving_default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e4ea54e-344e-48e8-8431-87955b622f8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'version': <tf.Tensor: shape=(), dtype=string, numpy=b'1.0.2-dev'>,\n",
       " 'outputs': <tf.Tensor: shape=(2, 1), dtype=float32, numpy=\n",
       " array([[0.49591082],\n",
       "        [0.49807087]], dtype=float32)>}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(sample_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e3842e6-2190-4b41-8a6d-38c330f68f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = new_model.signatures['guts']\n",
    "sample = g(sample_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29feb25a-4bcb-4b00-9fa0-d0e21f26f801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the      brain    of       ai       ai       is       over     <HYPHEN> time    \n",
      "the      brain    of       ai       ai       <OOV>    over     <HYPHEN> time     <EMPTY>  <EMPTY>  <EMPTY>  <EMPTY>  <EMPTY>  <EMPTY>  <EMPTY> \n",
      "--------------------------------\n",
      "once     upon     a        time     there    <APOSTROPHE-S> a        mid      <HYPHEN> century  brain    from     a        lot      of       over     <HYPHEN> time     that     he       <APOSTROPHE-S> not      there   \n",
      "<OOV>    upon     a        time     <OOV>    <APOSTROPHE-S> a        <OOV>    <HYPHEN> <OOV>    brain    from     a        <OOV>    of       over    \n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "for txt, vec in zip(sample['txt_output'].numpy(), sample['vec_output'].numpy()):\n",
    "    # txt = txt[0].decode('utf-8').split(' ')\n",
    "    print(\n",
    "        ' '.join(\n",
    "            [f'{i:<8}' for i in txt[0].decode('utf-8').split()]\n",
    "        )\n",
    "    )\n",
    "    dec = ' '.join([\n",
    "        f\"{sample['vocab'].numpy()[i].decode('utf-8'):<8}\" for i in vec\n",
    "    ])\n",
    "    print(dec)\n",
    "    print('-' * 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2b4b2f-4af7-4b23-bd7d-bba90f1b918f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
